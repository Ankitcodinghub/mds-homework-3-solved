# mds-homework-3-solved
**TO GET THIS SOLUTION VISIT:** [MDS Homework 3 Solved](https://www.ankitcodinghub.com/product/mds-homework-3-solved/)


---

ğŸ“© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
ğŸ“± **WhatsApp:** +1 419 877 7882  
ğŸ“„ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;91625&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;1&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (1 vote)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;MDS Homework 3 Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (1 vote)    </div>
    </div>
<ol>
<li><strong>(25%)Nov. 12 </strong>è³‡æ–™ç§‘å­¸æ‡‰ç”¨æ¡ˆä¾‹æ¼”è¬›
<ul>
<li><strong>(5%)</strong> è©²æ¼”è¬›å°æ‚¨ä¾†èªªå°è±¡æ·±åˆ»çš„ä¸»é¡Œç‚ºä½•ï¼Ÿç‚ºä»€éº¼ï¼Ÿè«‹æ‘˜è¦æ­¤æ·±åˆ»çš„ä¸»é¡Œã€‚å…¶å°æ‚¨ä¾†èªªå¸¶ä¾†çš„å•Ÿç™¼ç‚ºä½•ï¼Ÿ</li>
<li><strong>(5%) </strong>è©²æ¼”è¬›æ˜¯å¦æœ‰ç¿»è½‰/é¡›è¦†æ‚¨å°éå»è£½é€ æ¥­çš„èªçŸ¥ï¼Ÿå¦‚æœæœ‰ï¼Œä»€éº¼èªçŸ¥æœ‰äº†æ”¹è®Šï¼Ÿå¦‚æœç„¡ï¼Œä»€éº¼æ¨£çš„èªçŸ¥è·Ÿæ‚¨éå»çš„æ—¢å®šå°è±¡ä¸€æ¨£ï¼Œæ˜¯å¦æœ‰ä»»ä½•å»ºè­°æˆ–å¯æ”¹å–„ä¹‹è™•ï¼Ÿ</li>
<li><strong>(5%) </strong>è©²æ¼”è¬›è®“æ‚¨ç­è§£åˆ°è£½é€ æ¥­æ‡‰ç”¨æ•¸æ“šç§‘å­¸æ–¹æ³•çš„å›°é›£èˆ‡æŒ‘æˆ°åœ¨æ–¼ä½•è™•ï¼Ÿç‚ºä»€éº¼ï¼Ÿå¦‚ä½•å»ºè­°æˆ–è§£æ±ºï¼Ÿ</li>
<li><strong>(5%) </strong>æ¼”è¬›å…§å®¹ä¸­ï¼Œæ˜¯å¦æœ‰ä»»ä½•ç–‘é»ï¼Ÿæˆ–æƒ³å•è¬›è€…çš„å•é¡Œç‚ºä½•ï¼Ÿ</li>
<li><strong>(5%) </strong>åœ¨æ¼”è¬›å…§å®¹ä¸­ï¼Œæ˜¯å¦æœ‰ä»»ä½•æƒ³çµ¦äºˆå»ºè­°çš„åœ°æ–¹ï¼Ÿä¾‹å¦‚å•é¡Œåˆ‡å…¥é»ã€å•é¡Œæœ¬è³ªã€æ–¹æ³•èª¿æ•´ã€é©—è­‰çš„çœæ€ç­‰ã€‚</li>
</ul>
</li>
</ol>
<strong>&nbsp;</strong>

<ol start="2">
<li><strong>(40%) </strong>Decision Tree Algorithms</li>
</ol>
Data Source: <a href="https://www.kaggle.com/uciml/faulty-steel-plates">https://www.kaggle.com/uciml/faulty</a><a href="https://www.kaggle.com/uciml/faulty-steel-plates">â€“</a><a href="https://www.kaggle.com/uciml/faulty-steel-plates">steel</a><a href="https://www.kaggle.com/uciml/faulty-steel-plates">â€“</a><a href="https://www.kaggle.com/uciml/faulty-steel-plates">plates</a>

Dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117,

00128, Rome, Italy. <a href="http://www.semeion.it/">www.semeion.it</a>

&nbsp;

This dataset comes from research by Semeion, Research Center of Sciences of Communication. The original aim of the research was to correctly classify the type of surface defects in stainless steel plates, with six types of possible defects (plus â€œotherâ€). The Input vector was made up of

27 indicators that approximately describe the geometric shape of the defect and its outline.

&nbsp;

There are 1941 plates with 34 variables. The first 27 columns (i.e. independent variables) describe some kind of steel plate faults seen in images, i.e., X1-X27, as

{X_Minimum, X_Maximum, Y_Minimum, Y_Maximum, Pixels_Areas, X_Perimeter, Y_Perimeter

SumofLuminosity, MinimumofLuminosity, MaximumofLuminosity, LengthofConveyer, TypeOfSteel_A300, TypeOfSteel_A400, SteelPlateThickness, Edges_Index,Empty_Index,

Square_Index, OutsideXIndex, EdgesXIndex, EdgesYIndex, OutsideGlobalIndex, LogOfAreas,

LogXIndex, LogYIndex, Orientation_Index, Luminosity_Index, SigmoidOfAreas}

&nbsp;

The last seven columns (i.e. dependent variables) are one hot encoded classes, i.e. if the plate fault is classified as â€œStainsâ€ there will be a 1 in that column and 0â€™s in the other columns.

{Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults}

&nbsp;

These data can be found in <a href="http://archive.ics.uci.edu/ml/datasets/steel+plates+faults">http://archive.ics.uci.edu/ml/datasets/steel+plates+faults</a><a href="http://archive.ics.uci.edu/ml/datasets/steel+plates+faults">,</a> and are attached in the file <strong>MDS_Assignment3_Steelplates.xlsx</strong>.

<ul>
<li><strong>(5%)</strong> Construct a data science framework and show the data summary</li>
<li><strong>(5%) </strong>What is the problem about the dataset? Any identical column? Any redundant column? Any missing value? How to handle these issues?</li>
<li><strong>(5%)</strong> After data preprocessing, based on the <strong>prepared dataset</strong>, use the classification and regression tree (CART) to analyze the prepared dataset. Show the classification results by 10-fold cross validation with several metrics (eg. accuracy, area under ROC curve (AUC), and F1-score), and also list the hyperparameters you adjust.</li>
<li><strong>(5%) </strong>Suggest a method to address the data imbalance issue. Build a new balanced dataset.</li>
<li><strong>(5%) </strong>Based on the <strong>balanced dataset</strong>, use the classification and regression tree (CART) to analyze the balanced dataset. Show the classification results by 10-fold cross validation with several metrics (eg. accuracy, area under ROC curve (AUC), and F1-score), and also list the hyperparameters you adjust.</li>
<li><strong>(5%)</strong> Give a comparison between (c) and (e). Any suggestion or insight?</li>
<li><strong>(5%)</strong> Use â€œRandom Forestâ€ to solve both prepared dataset and balanced dataset, respectively. Give a comparison and provide your insight.</li>
<li><strong>(5%)</strong> Use â€œGradient Boosting Decision Tree (GBDT)â€ to solve both prepared dataset and balanced dataset, respectively. Give a comparison and provide your insight.</li>
</ul>
<ol start="3">
<li><strong> (20%) Deep Learning </strong></li>
</ol>
Use Python to build up Convolutional Neural Network (CNN) for â€œ<strong>casting product image data for quality inspection</strong>â€.

Data Source:

<a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">https://www.kaggle.com/ravirajsinh45/real</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">life</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">industrial</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">dataset</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">of</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">casting</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">â€“</a><a href="https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product">product</a>

Dataset provided by Pilot Technocast, Shapar, Rajkot <a href="https://pilottechnocast.com/">https://pilottechnocast.com/</a>

&nbsp;

This dataset is of casting manufacturing product. Casting is a manufacturing process in which a liquid material is usually poured into a mould, which contains a hollow cavity of the desired shape, and then allowed to solidify. Casting defect is an undesired irregularity in a metal casting process. There are many types of defect in casting like blow holes, pinholes, burr, shrinkage defects, mould material defects, pouring metal defects, metallurgical defects, etc. Defects are an unwanted thing in casting industry. For removing this defective product all industry have their quality inspection department. But the main problem is this inspection process is carried out manually. It is a very time-consuming process and due to human accuracy, this is not 100% accurate. This can because of the rejection of the whole order. So it creates a big loss in the company.

&nbsp;

We decided to make the inspection process automatic and for this, we need to make deep learning classification model for this problem. These all photos are top view of submersible pump impeller (google search for better understanding). For capturing these images requires stable lighting, for this we made a special arrangement.

We focus on the <strong>dataset with Augmentation</strong>: the dataset contains total 7348 image data. These all are the size of (300*300) pixels grey-scaled images. In all images, augmentation already applied. Making classification model we already split data for training and testing into two folders. Both train and test folder contains deffront and okfront subfolders.

train:- deffront have 3758 and okfront have 2875 images test:- deffront have:- deffront have 453 and ok_front have 262 images

&nbsp;

(The data set also includes the images size of 512Ã—512 grayscale without Augmentation. This

contains 519 okfront and 781 deffront impeller images. <strong>We donâ€™t focus on this data set</strong>.)

&nbsp;

Any question, you can google it (keyword: casting product image data for quality inspection) or refer to the following linkage. <a href="https://www.youtube.com/watch?v=4sDfwS48p0A">https://www.youtube.com/watch?v=4sDfwS48p0A</a>

If you would like to use Tensorflow, Keras, numpy, and pillow, you may refer to&nbsp; <a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">https://www.kaggle.com/ginsaputra/visual</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">inspection</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">of</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">casting</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">products</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">using</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">â€“</a><a href="https://www.kaggle.com/ginsaputra/visual-inspection-of-casting-products-using-cnn">cnn</a>

&nbsp;

(a) <strong>(20%)</strong> For CNN, try to investigate the effects of changing â€œ<strong>PARAMETERS</strong>â€ such as learning rates, momentum, # of hidden/convolutional layers, dropout rate, etc. Show the numerical results and â€œ<strong>DIAGRAM</strong>â€ from different perspectives (e.g., accuracy, F1-score, convergence time, error of training data, error of testing data, etc.). Please show all your work in detail, in particular, you â€œMAYâ€ need to design your <strong>experiments with different parameters </strong>systematically.

<strong>&nbsp;</strong>

<ol start="4">
<li><strong> (15%) Time-Series Prediction </strong></li>
</ol>
Use Python to build up long short-term memory (LSTM), which is one type of recurrent neural network (RNN). Collect the dataset related to <strong>weekly</strong> raw material price <strong>OR</strong> consumption (i.e. demand). Build a price/demand forecast. Donâ€™t use STOCK PRICE for prediction. You may read the tutorial: <a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">https://www.datacamp.com/community/tutorials/lstm</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">â€“</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">python</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">â€“</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">stock</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">â€“</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">market</a><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market">.</a> Note that, you only have price/demand data as response variable Y and it should be a <strong>time-rolling prediction</strong>, that is, for example, use the past 8 weeks dataset for 8-week ahead prediction. Thus, the prediction should be like the following diagram.

&nbsp;

&nbsp;

Dataset could be found as follows. eg. Brent oil price: <a href="https://www.investing.com/commodities/brent-oil-historical-data">https://www.investing.com/commodities/brent</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">â€“</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">oil</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">â€“</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">historical</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">â€“</a><a href="https://www.investing.com/commodities/brent-oil-historical-data">data</a>

Commodity prices: <a href="https://fred.stlouisfed.org/categories/32217">https://fred.stlouisfed.org/categories/32217</a>

Commodity prices: <a href="https://sdw.ecb.europa.eu/browse.do?node=9691219">https://sdw.ecb.europa.eu/browse.do?node=9691219</a>

The summary table of raw materials, <a href="https://just2.entrust.com.tw/z/ze/zeq/zeq.djhtm">https://just2.entrust.com.tw/z/ze/zeq/zeq.djhtm</a>

&nbsp;

Pick one raw material and collect its dataset. The collection period should be as long as possible (eg. from 2000 to 2020) to guarantee the sufficient samples for LSTM training.

<ul>
<li><strong>(10%)</strong> Prepare and transform the data to appropriate format (eg. use Data Generator in https://www.datacamp.com/community/tutorials/lstm-python-stock-market). Build LSTM model and show the prediction results via Time-series Nested Cross Validation.</li>
<li><strong>(5%)</strong> Visualize the time-rolling prediction as above diagram.<img data-recalc-dims="1" decoding="async" data-src="https://i0.wp.com/www.ankitcodinghub.com/wp-content/uploads/2022/06/591.png?w=980&amp;ssl=1" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" class="lazyload"></li>
</ul>
